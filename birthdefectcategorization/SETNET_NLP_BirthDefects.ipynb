{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96ba5e8",
   "metadata": {},
   "source": [
    "## SET-NET Birth Defects NLP Python Code: Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42349abb",
   "metadata": {},
   "source": [
    "Authors: Suzy Newton, Nicki Roth, Amy Board \\\n",
    "Last Updated: 03/31/2023 \\\n",
    "Purpose: To classify free text fields for birth defects into overarching categories for analysis \\\n",
    "\\\n",
    "This notebook will guide you through the steps for conducting text cleaning and classification of the bg_icd and bg_icd_sp fields. For additional guidance and a more in-depth overview of our approach to the classification process, please review the SOP for NLP for Birth Defects saved in this folder: \\\\cdc.gov\\locker\\NCBDDD_SET_NET\\SET-NET_Internal\\05_SET_NET_Data\\04_Data_Prep\\DSU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd835c90",
   "metadata": {},
   "source": [
    "## Libraries and setup\n",
    "\n",
    "Before running the cell below, make sure that you have installed the packages using the Anaconda command prompt. If you do not have Anaconda installed, you may download it here: https://www.anaconda.com/products/distribution. \\\n",
    "\\\n",
    "When running the cell below, you may get the following warning message: 'UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning.' You can ignore this message--it's in reference to the fuzzy matching process function we'll use later on, and it's just warning you that the fuzzy match might take a little while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# text processing and NLP\n",
    "import nltk\n",
    "import sklearn\n",
    "from nltk.tokenize import RegexpTokenizer,sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# fuzzy matching\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# So all output comes through from Ipython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Set the max number of rows to print out so the notebook is easier to read and navigate\n",
    "# You can increase this beyond 20 if you want\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "#Connecting to the SQL server\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a0250",
   "metadata": {},
   "source": [
    "## Check your working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb5735",
   "metadata": {},
   "source": [
    "Your working directory should point to wherever you cloned this GitHub repo. You can check your working directory like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab60cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory (if needed)\n",
    "## os.chdir(\"[GITHUB-REPO-LOCATION-HERE]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm it changed the working Directory\n",
    "print(\"My working directory:\\n\" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3fec4",
   "metadata": {},
   "source": [
    "## Import the dummy data file\n",
    "\n",
    "The NLP folder in this GitHub Repo contains a file of dummy data that can be used for learning purposes. If you are using this code with other data, you may need to clean and transform your dataset so it matches this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ad21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('synthetic_data.xlsx')\n",
    "\n",
    "data=data[['ID', 'bg_icd', 'bg_icd_sp']] #extra step to remove temporary notes columns\n",
    "\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24bf86",
   "metadata": {},
   "source": [
    "## Import and clean the ICD code reference list\n",
    "\n",
    "Now we need to import and clean the ICD code reference list so that we can match ICD codes and text data from the POB file and classify them accordingly. Be sure to update the file directory and/or filename as needed in the step below to make sure that the most current, up-to-date reference list is being pulled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2c813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = pd.read_excel('SETNET_birthdefects_codes_inclusion_forGitHub.xlsx')\n",
    "\n",
    "q.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 observations in the reference list\n",
    "# Check against the excel spreadsheet to ensure that everything looks correct\n",
    "\n",
    "q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of categories in the reference list\n",
    "# The resulting number should be 13 (1 more category will be added in later steps)\n",
    "\n",
    "q['Category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove periods and any other characters that might have been mistakenly added to the ICD code field\n",
    "remove = ['.',' ',',',';',':','_','?','!','(',')']\n",
    "\n",
    "for i in remove:\n",
    "    q['ICD'] = q['ICD'].str.replace(i,'',regex=True)\n",
    "\n",
    "\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681504b",
   "metadata": {},
   "source": [
    "## Explore and modify the POB data\n",
    "\n",
    "The steps below provide insight into the basic data structure, data types, and data composition. They also clean the bg_icd and bg_icd_sp codes in preparation for matching to the reference list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdb274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the number of null values in each column\n",
    "# If there are null (NaN) values in the columns, they will interfere with our analyses\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique ICD-10 codes\n",
    "\n",
    "data['bg_icd'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4c4fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a list of all unique ICD-10 codes in the dataset\n",
    "# A quick look at this list will inform whether additional cleaning steps need to be added to the steps below\n",
    "\n",
    "print(data.bg_icd.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388ab3c",
   "metadata": {},
   "source": [
    "The cell below conducts basic cleaning on the bg_icd field to match to the Q codes in the reference list. With each new quarterly data import, check to see if any additional cleaning steps are needed, such as additional punctuation or other values that don't belong. \\\n",
    "\\\n",
    "The goal is to match as many ICD codes to the reference list as possible, since the remaining text cleaning and matching processes are more prone to error and misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c2d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all codes to uppercase and drop any weird characters from field\n",
    "data['ICD'] = data['bg_icd'].str.upper() \n",
    "remove = ['.',' ',',',';',':','_','?','!','(',')','[',']']\n",
    "\n",
    "\n",
    "for i in remove:\n",
    "    data['ICD'] = data['ICD'].str.replace(i,'',regex=True)\n",
    "\n",
    "data['ICD'] = data['ICD'].replace(\"NONEREPORTED\",np.NaN)\n",
    "\n",
    "data[['ID','ICD','bg_icd','bg_icd_sp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict the newly cleaned dataset to only those observations that do not have missing ICD or bg_icd_sp\n",
    "\n",
    "data_new = data.loc[(data['ICD'].notnull()) & (data['ICD'] != \"\") | (data['bg_icd_sp'].notnull()), :].reset_index().copy()\n",
    "data_new\n",
    "data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb02e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100743c7",
   "metadata": {},
   "source": [
    "## Clean bg_icd_sp text\n",
    "\n",
    "Standardize and clean this text to be able to merge with reference text spreadsheet, and for hardcoding below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e85a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clean and turn text into a string\n",
    "remove = ['.',',',';',':','_','?','!','(',')','#']\n",
    "\n",
    "data_text = data_new.copy()\n",
    "for i in remove:\n",
    "    data_text['bg_icd_sp'] = data_text['bg_icd_sp'].str.replace(i,'', regex=True)\n",
    "    \n",
    "text = list(data_text['bg_icd_sp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a599ec",
   "metadata": {},
   "source": [
    "A significant number of observations are coming in as camel case text (for example: HeartDisease). We discovered that camel case interferes with the fuzzy matching process and results in a lower similarity index that might otherwise cause us to throw out a true match. The step below fixes the camel case text by adding a space in between text with a lowercase letter followed immediately by an uppercase letter and then makes all text values lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix camel case text\n",
    "text_new=[]\n",
    "\n",
    "for i in text:\n",
    "    i = str(i)\n",
    "    a = re.sub(r'((?<=[a-z])[A-Z]|(?<!\\A)[A-Z](?=[a-z]))', r' \\1',i).lower()\n",
    "    text_new.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff834a83",
   "metadata": {},
   "source": [
    "Now that the text has been cleaned and standardized, we will merge the cleaned bg_icd_sp field back into the pob3 dataframe so we can use this later when we merge with the ICD text reference spreadsheet and when we perform the NLP steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the clean text field back into merged_dta for later use with NLP\n",
    "bg_icd_sp_clean = pd.DataFrame(text_new, columns = ['bg_icd_sp_clean']).reset_index()\n",
    "\n",
    "data_clean = pd.merge(data_new, bg_icd_sp_clean, left_index=True, right_index=True)\n",
    "data_clean.drop(['index_x', 'index_y'], axis=1, inplace=True)\n",
    "data_clean['ICD'] = data_clean['ICD'].astype(str)\n",
    "\n",
    "#Drop old columns\n",
    "data_clean=data_clean.drop(['bg_icd','bg_icd_sp'], axis=1) #'level_0'], axis=1) #removing level_0 from drop\n",
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873ccf2",
   "metadata": {},
   "source": [
    "## Merge POB data to Q code reference list\n",
    "\n",
    "Now that the ICD codes have been cleaned and we've set those we can based on their reviewed text, we can merge the POB data and the reference list together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d55441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = data_clean.merge(q, how='left', on='ICD')\n",
    "\n",
    "merged.info()\n",
    "\n",
    "# View NaN values in Category in the resulting merged dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "merged[merged[\"Category\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc98af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the shape of the resulting dataset meets expectations (e.g., number of columns, number of rows)\n",
    "merged.shape\n",
    "\n",
    "# Run a quick summary of numbers of observations in each category\n",
    "merged.groupby('Category').count().sort_values('Text',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d0c03",
   "metadata": {},
   "source": [
    "\n",
    "## Match modified ICD-9 codes\n",
    "\n",
    "Massachussetts sends modified ICD-9 codes, which are numbers and start with 7 usually. The columns Mod_ICD9_low and\tMod_ICD9_high contain the reference values we will use to match the modified ICD-9 code with the correct birth defect text and category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict to Massachussetts rows\n",
    "MACDP_data = merged.loc[merged['ICD'].str.startswith('7')].copy()\n",
    "\n",
    "#Convert ICD to numeric\n",
    "MACDP_data['ICD'] = MACDP_data['ICD'].astype(int)\n",
    "\n",
    "#Restrict to columns needed\n",
    "MACDP_data = MACDP_data[['ID','ICD']]\n",
    "MACDP_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b4916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating modified ICD-9 dictionary\n",
    "MACDP = q.loc[q['Mod_ICD9_low'].notnull(), :].copy()\n",
    "MACDP.head()\n",
    "#Restrict to columns needed\n",
    "MACDP = MACDP[['Mod_ICD9_low','Mod_ICD9_high','Text','Category']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert ICD 9 columns to integers\n",
    "MACDP['Mod_ICD9_low']=MACDP['Mod_ICD9_low'].astype(int)\n",
    "MACDP['Mod_ICD9_high']=MACDP['Mod_ICD9_high'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e485e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataframes and assign text and category for each row in MAS\n",
    "MACDP_data_assigned = MACDP_data.assign(key=1).merge(MACDP.assign(key=1), on='key')\\\n",
    "                 .drop(columns='key')\\\n",
    "                 .query('ICD.between(Mod_ICD9_low, Mod_ICD9_high)')\\\n",
    "                 .drop(columns=['Mod_ICD9_low', 'Mod_ICD9_high'])\\\n",
    "                 .reset_index(drop=True)\n",
    "MACDP_data_assigned['ICD'] = MACDP_data_assigned['ICD'].astype(str)\n",
    "MACDP_data_assigned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge assigned MAS cases back into full dataframe\n",
    "merged = merged[['ID','ICD','bg_icd_sp_clean','Text','Category']] \n",
    "merged_new= merged.merge(MACDP_data_assigned, how='left', on=['ID','ICD'])\n",
    "\n",
    "merged_new.head()\n",
    "merged_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab881f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Text_y column with values from Text_x where Text_y is NaN, and rename Text_y\n",
    "merged_new['Text'] = merged_new['Text_x'].fillna(merged_new['Text_y'])\n",
    "merged_new['Category'] = merged_new['Category_x'].fillna(merged_new['Category_y'])\n",
    "\n",
    "merged_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed1313",
   "metadata": {},
   "source": [
    "## Hard-code classifications for specific observations\n",
    "\n",
    "Some ICD codes and text have been incorrectly reported in the bg_icd and bg_icd_sp variables and are not, in fact, birth defects. Others provide too little information to classify, such as test results that are pending. Additionally, some text values occur frequently enough that it's worth hard-coding those observations into their specific categories to ensure the steps above have classified them appropriately and to improve overall accuracy of the NLP model. \n",
    "\n",
    "The steps below conduct hard-coding of these classifications in the merged_dta dataframe. With new data submissions, additional hard-coding may be required. Refer to the analyst SOP and clinical review SOP for additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop old columns\n",
    "merged_clean=merged_new.drop(['Category_x','Category_y','Text_x','Text_y'], axis=1)\n",
    "merged_clean.shape\n",
    "merged_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7729b21",
   "metadata": {},
   "source": [
    "Create a separate dataset of all observations with missing ICD code or non-matching ICD codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb629dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Qmiss = merged_clean.loc[merged_clean['Category'].isnull(), :].copy()\n",
    "Qmiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a310c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Qmiss.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2909ebf",
   "metadata": {},
   "source": [
    "Now re-classify observations with text that contains the words \"pending\" or \"suspected\" as unable to classify, and also re-classify observations with text or ICD codes that indicate something that is not actually a birth defect. Add some additional categories for hard-coding: 1) observations that are not a birth defect based on ICD code (e.g., non-Q codes), and 2) commonly occurring text (or text values that otherwise need to be hard-coded). For more information, see the analytic SOP and clinical review SOP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bdd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recoding observations as \"Not a birth defect of interest/Unable to classify\"\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean']=='other'),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean']=='other '),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean']=='a'),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean']=='other anomaly'),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean']=='other  anomaly'),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains(\"pending\")),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains(\"suspected\")),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.find(\"tongue tie\",0)>=0),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('sacral dimple')),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains(\"possible\")),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains(\"Notabirthdefectofinterest/Unabletoclassify\")),'Not a birth defect of interest/Unable to classify',Qmiss['Category'])\n",
    "\n",
    "# Recoding observations as \"Not a birth defect\" based on text data\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('murmur')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.find(\"mongolian\",0)>=0),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('nevus')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('tachycardia')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('glycemia')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('non-viable fetus')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('small for gestational age')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('large for gestational age')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('caput')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('hernia umbilical')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('umbilical hernia')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('phimosis')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('hydrocele')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('anemia')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('premature infant')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('stillbirth')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['bg_icd_sp_clean'].str.contains('respiratory distress')),'Not a birth defect',Qmiss['Category'])\n",
    "\n",
    "# Recoding observations as \"Not a birth defect\" based on ICD code\n",
    "Qmiss.loc[Qmiss['ICD'].str.contains(r\"^[a-pr-zA-PR-Z][0-9]+$\", regex=True), 'Category'] = 'Not a birth defect'\n",
    "\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains('TERMINALMECOMIUN')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains('FORAMENOVULEANEURYSM')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains('VENTRA')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains('ANEMIA')),'Not a birth defect',Qmiss['Category'])\n",
    "Qmiss['Category'] = np.where((Qmiss['ICD'].str.contains('Notabirthdefect')),'Not a birth defect',Qmiss['Category'])\n",
    "\n",
    "Qmiss['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d516cd9",
   "metadata": {},
   "source": [
    "Now we can remove these rows that have been hardcoded from Qmiss and will later add them into the NoMiss dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade88465",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmiss2 = Qmiss.loc[Qmiss['Category'].isnull(), :].copy()\n",
    "\n",
    "Qmiss2.shape\n",
    "\n",
    "nomiss_new = Qmiss.loc[Qmiss['Category'].notnull(), :].copy()\n",
    "\n",
    "nomiss_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict Qmiss to relevant columns\n",
    "Qmiss2 = Qmiss2[['ID','bg_icd_sp_clean','ICD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f624df8",
   "metadata": {},
   "source": [
    "The reference list of Q codes that we are using is a living document. It represents all Q codes that are currently present within the POB data. With each new data import, we need to manually check the list of nonmatching ICD codes in Qmiss to see if there are any new Q codes that haven't previously been included in the dataset. These codes should be added to the reference list and categorized accordingly based on clinical review.\\\n",
    "\\\n",
    "IMPORTANT: After the new Q codes have been categorized, you must re-run each of the steps above so that the ICD codes in the POB dataset can be matched with the newly-categorized ICD codes. Remember, the more observations we can match on ICD code, the more robust our model will be, and the fewer observations we will have left to try to predict their classifications using NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e00f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review non-matching Q codes to see if any need to be added to the reference list\n",
    "Qmiss_review = Qmiss2[Qmiss2['ICD'].astype(str).str.contains('Q')].copy()\n",
    "Qmiss_review\n",
    "\n",
    "# If the list is too long to review in the Jupyter notebook, you can export to an excel file using the code below:\n",
    "##############################Qmiss_review.to_excel('Qmiss_review.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38353100",
   "metadata": {},
   "source": [
    "Create a separate dataset of all observations with matching ICD codes, which we will use to build our NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77cb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomiss = merged_clean.loc[merged_clean['bg_icd_sp_clean'].notnull() & (merged_clean['Category'].notnull()), :].copy()\n",
    "\n",
    "nomiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d098ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomiss2 = pd.concat([nomiss, nomiss_new])\n",
    "\n",
    "nomiss2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184555e",
   "metadata": {},
   "source": [
    "Plot the frequencies of observations for each birth defect category in nomiss. This will give us an idea of the number of data elements we are supplying for the model, and indicates that stratified sampling is necessary for the model because our data is highly imbalanced between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9694f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = sns.countplot(x=nomiss2['Category'], order=pd.value_counts(nomiss2['Category']).index)\n",
    "sns.set(rc = {'figure.figsize':(20,5)},font_scale=2)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d987038",
   "metadata": {},
   "source": [
    "## Fuzzy matching: Non-categorized observations\n",
    "\n",
    "Observations with missing or nonmatching ICD values in Qmiss might have text in bg_icd_sp_clean that matches exactly or very nearly to a Q code ICD description. If we can match some observations through fuzzy matching, we can add those matched values to nomiss, develop a more robust NLP model, and we are left with fewer unclassified observations that we would have to predict using ML.\\\n",
    "\\\n",
    "We will use the fuzzywuzzy package for Python to conduct the fuzzy matching against the ICD code description text in the reference list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn text from q2 into a list of strings and make all characters lowercase\n",
    "ref_vals = list(q['Text'].str.lower())\n",
    "ref_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b291c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn text from Qmiss into a string\n",
    "unmatched = list(Qmiss2['bg_icd_sp_clean'])\n",
    "unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6bc4b",
   "metadata": {},
   "source": [
    "Use the process function in the fuzzywuzzy package to identify the reference ICD code description value with the closest match to the bg_icd_sp text in Qmiss. The step below prints out the ICD code description that is the closest match to the text field in one row and the similarity index for the match in the following row. We create a for loop that will run each bg_icd_sp value through the entire list of ICD code descriptions from the reference list and put the results into a dataframe.\\\n",
    "\\\n",
    "Note that this step can take a few minutes to run on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95925801",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_results = {'Matched Value':[], 'FW_score':[], 'bg_icd_sp_clean':[]}\n",
    "\n",
    "highest = process.extractOne(i, ref_vals)\n",
    "\n",
    "for i in unmatched:\n",
    "    highest = process.extractOne(i,ref_vals)\n",
    "    match_results['Matched Value'].append(highest[0])\n",
    "    match_results['FW_score'].append(highest[1])\n",
    "    match_results['bg_icd_sp_clean'].append(i)\n",
    "\n",
    "        \n",
    "clean_fw_results = pd.DataFrame(match_results)\n",
    "clean_fw_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae98534",
   "metadata": {},
   "source": [
    "Now that we have the fuzzy matching results lined up nicely to the bg_icd_sp_clean values, we'll merge these results with the original Qmiss dataframe so that these values are linked to participant ID. Note that when you perform the steps below, you may observe that a handful of observations were dropped from the steps above. This is not a mistake! In the current dataset, there are a few IDs that have duplicated bg_icd and bg_icd_sp fields (e.g., the same ICD code and text description repeated twice for the same participant ID in bg_icd1/bg_icd1_sp and bg_icd2/bg_icd2_sp). These are genuine duplicates and should be dropped. If you want to be extra sure, you can export Qmiss to an excel workbook and use the \"highlight duplicate values\" feature in conditional formatting to do a manual check and ensure it is only true duplicates that are being dropped in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fw_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14919033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now combine with original dataframe\n",
    "miss_fw_matched = pd.merge(Qmiss2, clean_fw_results, how='left', on='bg_icd_sp_clean').drop_duplicates()\n",
    "\n",
    "miss_fw_matched.rename(columns={'ICD':'ICD_orig'}, inplace = True)\n",
    "miss_fw_matched.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cacab",
   "metadata": {},
   "source": [
    "Now we will merge with the reference dataset on ICD description values so that we have the associated category for the matched values. Note that we will need to drop duplicates again, but this time, it's for another reason. The reference list includes some parent ICD codes that have the same ICD text description as certain child codes (e.g., parent and child codes for cleft lip). When we match the two dataframes on ICD description values, we end up with duplicate values for those observations for all but ICD code, because the text description matches to more than one ICD code. To solve this, we drop all values that have a duplicate ID, bg_icd, bg_icd_sp, and Text field. It doesn't matter which ICD code is retained for those values because all we're interested in ultimately is the Category, and the codes with matching ICD text will be assigned to the same Category of birth defects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c031105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with reference dataset\n",
    "qnew = q\n",
    "qnew['Matched Value'] = q['Text'].str.lower()\n",
    "\n",
    "\n",
    "miss_fw_matched2 = pd.merge(miss_fw_matched, qnew, how='left', on='Matched Value')\n",
    "\n",
    "# Drop duplicate observations where ID, bg_icd_sp, and Text are all the same.\n",
    "miss_fw_matched2 = miss_fw_matched2.drop_duplicates(subset=['ID','bg_icd_sp_clean','Text'])\n",
    "\n",
    "miss_fw_matched2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd75469",
   "metadata": {},
   "source": [
    "Now you can export this dataframe to an excel document that will allow for clinical review of the fuzzy match results. Currently, our cutoff value is a similarity score of 90% or higher for something to be considered a \"true\" match. For observations with a cutoff value of 90% or higher, we will assign the associated birth defect category to the matching ICD code and text description. However, as new data submissions come in, you will want to check the results as described in the clinical review SOP to ensure that 90% is still an approporiate cutoff value. Use the step below to export the dataframe, updating the date of the filename accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export an excel file with these results\n",
    "\n",
    "##############################miss_fw_matched2.to_excel('Fuzzy_Matching_Qmiss_March2023.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de4f0c",
   "metadata": {},
   "source": [
    "## Preparing the data for ML\n",
    "\n",
    "Now that we've done fuzzy matching, we want to update the Qmiss and noMiss dataframes to accommodate these additional values before we develop our NLP model. \n",
    "\n",
    "miss_fw_matched2 now has a number of observations that are classified due to a fuzzy match similarity score of 90% or greater or due to hard-coding of observations. We want to extract these observations and add them to nomiss, which will increase the robustness of our training and testing data for NLP. To do this, we will flag all of the observations in Qmiss that have now been accurately classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eaa15a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pull out values from miss_fw_matched2 that are now classified due to a fuzzy match score of >=90%\n",
    "# Create a flag variable\n",
    "miss_fw_matched2['classified_flag'] = np.where((miss_fw_matched2['FW_score'] > 89),1,0)\n",
    "\n",
    "miss_fw_matched2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a887e",
   "metadata": {},
   "source": [
    "Classified_flag values that equal 1 will be extracted from Qmiss_clean2 and joined to a final version of nomiss to be used to build our NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values to be added to Nomiss\n",
    "miss_fw_matched3 = miss_fw_matched2.loc[miss_fw_matched2['classified_flag']==1].drop(['Matched Value',\n",
    "                                                                           'FW_score','classified_flag','ICD_orig'],axis='columns').copy()\n",
    "miss_fw_matched3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d985871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with nomiss\n",
    "nomiss3 = pd.concat([nomiss2, miss_fw_matched3],ignore_index = True)\n",
    "nomiss3.shape\n",
    "nomiss3=nomiss3.drop(['Mod_ICD9_low','Mod_ICD9_high'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a131103",
   "metadata": {},
   "source": [
    "Now subset miss_fw_matched2 to only those observations with a classified_flag value of 0. These are the remaining unclassified observations in the dataset that will be classified using NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to remaining unclassified values for classification using NLP modeling\n",
    "Qmiss3 = miss_fw_matched2.loc[miss_fw_matched2['classified_flag']==0].drop(\n",
    "     ['classified_flag','Matched Value','FW_score','Category','ICD', 'Text','Mod_ICD9_low','Mod_ICD9_high'],axis='columns').reset_index().copy()\n",
    "Qmiss3.rename(columns={'ICD_orig':'ICD'}, inplace = True)\n",
    "Qmiss3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115144be",
   "metadata": {},
   "source": [
    "# Now it's time for some NLP!\n",
    "\n",
    "We will build our NLP classification model using nomiss3, test various models to identify the one with the greatest accuracy, and run the final model on Qmiss3 to classify the unclassified text.\n",
    "\n",
    "We are using the sklearn package for the NLP and machine learning. First we need to split our data into training and validation datasets based on our text data ('bg_icd_sp_clean') and associated classifications ('Category'). Because our data is heavily imbalanced with each category of birth defects occurring with a different frequency, we need to stratify our training and validation datasets by category. We are using a 75%/25% training/validation split, and we've indicated a random state seed for the purposes of reproducibility (but the steps below could also be run without indicating a random state seed number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#split into training and testing data\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(nomiss3['bg_icd_sp_clean'], nomiss3['Category'], stratify=nomiss3['Category'],\n",
    "                     test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ced17",
   "metadata": {},
   "source": [
    "Now we need to use TfidfVectorizer to transform and process our text data for the model. Our first approach is to do this using unigrams, and we also remove stop words using the built-in function for English stop words such as 'on', 'a', 'the', etc.\n",
    "\n",
    "There is also an option to determine max features for the vectorizer, but we have removed max features for the time being.\n",
    "\n",
    "After vectorizing our data, we fit to the training dataset and transform the raw text for each of our training and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = TfidfVectorizer(stop_words=\"english\",lowercase=True)\n",
    "\n",
    "# fit only on the training data\n",
    "unigrams.fit(X_train)\n",
    "\n",
    "## transform raw text\n",
    "tfidf_unigrams_train = unigrams.transform(X_train)\n",
    "tfidf_unigrams_valid = unigrams.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486818d6",
   "metadata": {},
   "source": [
    "Use get_feature_names to check that the data was vectorized as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512abc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e438e",
   "metadata": {},
   "source": [
    "Check the shape of the datasets and the vectorized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b718c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigrams_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee53a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigrams_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea8a7fe",
   "metadata": {},
   "source": [
    "Now we will vectorize the data again but for the purposes of performing cross-validation of each of our models. The difference here is that for cross-validation, the full dataset is vectorized, and not just the training data, as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "unigrams_cv = TfidfVectorizer(stop_words='english', lowercase= True)\n",
    "\n",
    "# For cross-validation, fit on all of the training and testing data\n",
    "unigrams_cv.fit(nomiss3['bg_icd_sp_clean'])\n",
    "\n",
    "tfidf_unigrams_cv = unigrams_cv.transform(nomiss3['bg_icd_sp_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigrams_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4c1ec",
   "metadata": {},
   "source": [
    "For cross-validation, we also need to create a separate text array that contains our classified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = np.asarray(nomiss3['Category'])\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87bf5f",
   "metadata": {},
   "source": [
    "Now we will go through each of the steps above again but this time to create vectorized data as bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c16115",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = TfidfVectorizer(stop_words=\"english\",lowercase=True, ngram_range=(2,2))\n",
    "\n",
    "# fit only on the training data\n",
    "bigrams.fit(X_train)\n",
    "\n",
    "## transform raw text\n",
    "tfidf_bigrams_train = bigrams.transform(X_train)\n",
    "tfidf_bigrams_valid = bigrams.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc490f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bigrams_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bigrams_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "bigrams_cv = TfidfVectorizer(stop_words='english', lowercase= True, ngram_range=(2,2))\n",
    "\n",
    "# For cross-validation, fit on all of the training and testing data\n",
    "bigrams_cv.fit(nomiss3['bg_icd_sp_clean'])\n",
    "\n",
    "tfidf_bigrams_cv = bigrams_cv.transform(nomiss3['bg_icd_sp_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fda2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bigrams_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c6507",
   "metadata": {},
   "source": [
    "Now we will go through each of the steps above again but this time to create vectorized data as trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = TfidfVectorizer(stop_words=\"english\",lowercase=True, ngram_range=(3,3))\n",
    "\n",
    "# fit only on the training data\n",
    "trigrams.fit(X_train)\n",
    "\n",
    "## transform raw text\n",
    "tfidf_trigrams_train = trigrams.transform(X_train)\n",
    "tfidf_trigrams_valid = trigrams.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde34b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_trigrams_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trigrams_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674317dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "trigrams_cv = TfidfVectorizer(stop_words='english', lowercase= True, ngram_range=(3,3))\n",
    "\n",
    "# For cross-validation, fit on all of the training and testing data\n",
    "trigrams_cv.fit(nomiss3['bg_icd_sp_clean'])\n",
    "\n",
    "tfidf_trigrams_cv = trigrams_cv.transform(nomiss3['bg_icd_sp_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trigrams_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41788345",
   "metadata": {},
   "source": [
    "# Developing NLP model using unigrams\n",
    "\n",
    "We are testing three different models to see which one has the highest accuracy: Multinomial Naive Bayes, Multi-layer Perceptron (MLP) Classifier, and Random Forest Classifier. We will run each model using unigrams, bigrams, and trigrams, and compare accuracy scores to see which approach classifies our data best.\n",
    "\n",
    "The first model we will test with unigrams is Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4e1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod1_nb = MultinomialNB().fit(tfidf_unigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "mod1_nb_train = mod1_nb.predict(tfidf_unigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, mod1_nb_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, mod1_nb_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, mod1_nb_train))\n",
    "\n",
    "# validation results\n",
    "mod1_nb_valid = mod1_nb.predict(tfidf_unigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, mod1_nb_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, mod1_nb_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, mod1_nb_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c0e55",
   "metadata": {},
   "source": [
    "Now that we have run Multinomial Naive Bayes using unigrams with the training and validation datasets, we will run a cross-validation of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of first model\n",
    "mod1_nb = MultinomialNB()\n",
    "#scores = cross_val_score(mod1_nb, tfidf_unigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "mod1_nb = MultinomialNB()\n",
    "scores = cross_val_score(mod1_nb, tfidf_unigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1_nb_cv = cross_val_predict(mod1_nb, tfidf_unigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv,mod1_nb_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44878e",
   "metadata": {},
   "source": [
    "Now we will follow the same steps above to run our unigrams with our second model, MLP Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be34eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500).fit(tfidf_unigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_mlp_train = clf_mlp.predict(tfidf_unigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_mlp_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_mlp_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_mlp_train))\n",
    "\n",
    "# validation results\n",
    "clf_mlp_valid = clf_mlp.predict(tfidf_unigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_mlp_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_mlp_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_mlp_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c196d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of second model\n",
    "#clf_mlp = MLPClassifier(random_state=1, max_iter=500)\n",
    "#scores = cross_val_score(clf_mlp, tfidf_unigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500)\n",
    "scores = cross_val_score(clf_mlp, tfidf_unigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6bd133",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp_cv = cross_val_predict(clf_mlp, tfidf_unigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "#sklearn.metrics.accuracy_score(y_cv, clf_mlp_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53969baf",
   "metadata": {},
   "source": [
    "The training and validation datasets performed much better using the MLP Classifier model, although the cross-validation scores were considerably lower. \n",
    "\n",
    "Now we will try the random forest classifier model using unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d93e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1).fit(tfidf_unigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_rf_train = clf_rf.predict(tfidf_unigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_rf_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_rf_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_rf_train))\n",
    "\n",
    "# validation results\n",
    "clf_rf_valid = clf_rf.predict(tfidf_unigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_rf_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_rf_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_rf_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of third model\n",
    "#clf_rf = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "#scores = cross_val_score(clf_rf, tfidf_unigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_rf = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "scores = cross_val_score(clf_rf, tfidf_unigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_cv = cross_val_predict(clf_rf, tfidf_unigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv,clf_rf_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf68e9",
   "metadata": {},
   "source": [
    "Among unigrams, the model with the highest accuracy scores is the MLP Classifier model, built on the training dataset. We will use that model to categorize our unclassified data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144f798",
   "metadata": {},
   "source": [
    "# Developing NLP model using bigrams\n",
    "\n",
    "We want to continue our model testing and development by exploring how the accuracy of our models change when we use bigrams instead of unigrams. We will conduct all the same steps above for bigrams and compare the accuracy scores to the unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22fbd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First model: Multinomial Naive Bayes\n",
    "mod2_nb = MultinomialNB().fit(tfidf_bigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "mod2_nb_train = mod2_nb.predict(tfidf_bigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, mod2_nb_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, mod2_nb_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, mod2_nb_train))\n",
    "\n",
    "# validation results\n",
    "mod2_nb_valid = mod2_nb.predict(tfidf_bigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, mod2_nb_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, mod2_nb_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, mod2_nb_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70946d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of first model\n",
    "#mod2_nb = MultinomialNB()\n",
    "#scores = cross_val_score(mod2_nb, tfidf_bigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "mod2_nb = MultinomialNB()\n",
    "scores = cross_val_score(mod2_nb, tfidf_bigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba54935",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2_nb_cv = cross_val_predict(mod2_nb, tfidf_bigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv,mod2_nb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b2049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Second model: MLP Classifier\n",
    "clf_mlp2 = MLPClassifier(random_state=1, max_iter=500).fit(tfidf_bigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_mlp2_train = clf_mlp2.predict(tfidf_bigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_mlp2_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_mlp2_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_mlp2_train))\n",
    "\n",
    "# validation results\n",
    "clf_mlp2_valid = clf_mlp2.predict(tfidf_bigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_mlp2_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_mlp2_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_mlp2_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28650224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of second model\n",
    "#clf_mlp2 = MLPClassifier(random_state=1, max_iter=500)\n",
    "#scores = cross_val_score(clf_mlp2, tfidf_bigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_mlp2 = MLPClassifier(random_state=1, max_iter=500)\n",
    "scores = cross_val_score(clf_mlp2, tfidf_bigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp2_cv = cross_val_predict(clf_mlp2, tfidf_bigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv,clf_mlp2_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model: Random Forest Classifier\n",
    "clf_rf2 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1).fit(tfidf_bigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_rf2_train = clf_rf2.predict(tfidf_bigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_rf2_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_rf2_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_rf2_train))\n",
    "\n",
    "# validation results\n",
    "clf_rf2_valid = clf_rf2.predict(tfidf_bigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_rf2_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_rf2_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_rf2_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c136802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of third model\n",
    "#clf_rf2 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "#scores = cross_val_score(clf_rf2, tfidf_bigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_rf2 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "scores = cross_val_score(clf_rf2, tfidf_bigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace27d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2_cv = cross_val_predict(clf_rf2, tfidf_bigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv, clf_rf2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d47246",
   "metadata": {},
   "source": [
    "# Developing NLP model using trigrams\n",
    "\n",
    "Finally, we will run through all of these steps again using trigrams to see if model performance is improved compared to unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First model: Multinomial Naive Bayes\n",
    "mod3_nb = MultinomialNB().fit(tfidf_trigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "mod3_nb_train = mod3_nb.predict(tfidf_trigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, mod3_nb_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, mod3_nb_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, mod3_nb_train))\n",
    "\n",
    "# validation results\n",
    "mod3_nb_valid = mod3_nb.predict(tfidf_trigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, mod3_nb_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, mod3_nb_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, mod3_nb_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e94bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of first model\n",
    "#mod3_nb = MultinomialNB()\n",
    "#scores = cross_val_score(mod3_nb, tfidf_trigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "mod3_nb = MultinomialNB()\n",
    "scores = cross_val_score(mod3_nb, tfidf_trigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65031a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3_nb_cv = cross_val_predict(mod3_nb, tfidf_trigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.accuracy_score(y_cv, mod3_nb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second model: MLP Classifier\n",
    "clf_mlp3 = MLPClassifier(random_state=1, max_iter=500).fit(tfidf_trigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_mlp3_train = clf_mlp3.predict(tfidf_trigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_mlp3_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_mlp3_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_mlp3_train))\n",
    "\n",
    "# validation results\n",
    "clf_mlp3_valid = clf_mlp3.predict(tfidf_trigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_mlp3_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_mlp3_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_mlp3_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of second model\n",
    "#clf_mlp3 = MLPClassifier(random_state=1, max_iter=500)\n",
    "#scores = cross_val_score(clf_mlp3, tfidf_trigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_mlp3 = MLPClassifier(random_state=1, max_iter=500)\n",
    "scores = cross_val_score(clf_mlp3, tfidf_trigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp3_cv = cross_val_predict(clf_mlp3, tfidf_trigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.f1_score(y_cv, clf_mlp3_cv, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75666992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model: Random Forest Classifier\n",
    "clf_rf3 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1).fit(tfidf_trigrams_train, y_train)\n",
    "\n",
    "# train results \n",
    "clf_rf3_train = clf_rf3.predict(tfidf_trigrams_train)\n",
    "print('accuracy', accuracy_score(y_train, clf_rf3_train))\n",
    "print('confusion matrix\\n', confusion_matrix(y_train, clf_rf3_train))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_train, clf_rf3_train))\n",
    "\n",
    "# test results\n",
    "clf_rf3_valid = clf_rf3.predict(tfidf_trigrams_valid)\n",
    "print('accuracy', accuracy_score(y_valid, clf_rf3_valid))\n",
    "print('confusion matrix\\n', confusion_matrix(y_valid, clf_rf3_valid))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(classification_report(y_valid, clf_rf3_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation of third model\n",
    "#clf_rf3 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "#scores = cross_val_score(clf_rf3, tfidf_trigrams_cv, y_cv, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#print(scores)\n",
    "#print(np.mean(scores))\n",
    "clf_rf3 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "scores = cross_val_score(clf_rf3, tfidf_trigrams_cv, y_cv, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf3_cv = cross_val_predict(clf_rf3, tfidf_trigrams_cv, y_cv, cv=5, n_jobs=-1)\n",
    "sklearn.metrics.f1_score(y_cv, clf_rf3_cv, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd7f73",
   "metadata": {},
   "source": [
    "## Merge the classified results into a single dataset\n",
    "\n",
    "Since the unigrams results with MLP Classifier were the most accurate, we will consider these to be our true categories and will merge their data with nomiss_clean3 so we have a full, classified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmiss4 = Qmiss3[['ID','ICD','bg_icd_sp_clean']].copy()\n",
    "Qmiss4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with the highest accuracy\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=500).fit(tfidf_unigrams_train, y_train)\n",
    "\n",
    "# transform raw text in Qmiss\n",
    "tfidfQmiss_uni = unigrams.transform(Qmiss3['bg_icd_sp_clean'])\n",
    "tfidfQmiss_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data = pd.Series(clf_mlp.predict(tfidfQmiss_uni))\n",
    "classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmiss_classified = pd.concat([Qmiss4,classified_data],axis=1)\n",
    "Qmiss_classified.rename(columns={0:\"Category\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save separate dataset for just the Qmiss observations categorized \n",
    "# by our model\n",
    "##############################Qmiss_classified.to_excel('Missing Q codes_classified_Mar2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e265da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Qmiss_classified with nonmissing\n",
    "POB_final = pd.concat([nomiss3, Qmiss_classified],ignore_index = True)\n",
    "POB_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset\n",
    "# Be sure to change the date in the filename!\n",
    "##############################POB_final.to_excel('POB Birth Defects Classified_NLP_Mar2023.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2cb03",
   "metadata": {},
   "source": [
    "Congratulations! You have now cleaned the POB birth defects data and classified each observation into a birth defect category.\n",
    "\n",
    "If you have any questions about this code, contact Suzy Newton, Nicki Roth, or Amy Board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
